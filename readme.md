![foundry_logo](Images/AI%20Foundry%20Logo_RGB_Full%20Colour.png)

# AI Best Practice Resources ![awesome_logo](Images/awesome_list_logo_small.png)

A list curated by the Greater Manchester AI Foundry[^1] to provide resources on and promote best practice with respect to the development of AI.

Links have been selected with the aim of helping AI developers navigate the latest regulations, practices, and research.

The contribution guidelines can be found [here](contributing.md).

## Governing / Advisory Bodies

- ğŸŒ [The Alan Turing Institute](https://www.turing.ac.uk/)
- ğŸŒ [The Institute for Ethical AI & Machine Learning](https://ethical.institute/)
- ğŸŒ [Centre for Data Ethics and Innovation](https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation)
- ğŸŒ [European AI Alliance](https://futurium.ec.europa.eu/en/european-ai-alliance)
- ğŸŒ [Ada Lovelace Institute](https://www.adalovelaceinstitute.org/just-ai/)

## Regulation / Strategy

- ğŸŒ [National AI Strategy](https://www.gov.uk/government/news/new-strategy-to-unleash-the-transformational-power-of-artificial-intelligence) (UK national AI strategy published 2021)
- ğŸ“œ [AI, human rights, democracy and the rule of law: A primer prepared for the Council of Europe](https://www.turing.ac.uk/research/publications/ai-human-rights-democracy-and-rule-law-primer-prepared-council-europe)
- ğŸ“œ [European Commission - Ethics and Data Protection](https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/horizon/guidance/ethics-and-data-protection_he_en.pdf)

## Toolkits / Best Practice

- ğŸ› ï¸ [Microsoft Responsible Innovation Toolkit](https://docs.microsoft.com/en-us/azure/architecture/guide/responsible-innovation/)
- ğŸ“œ [Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI](https://dl.acm.org/doi/10.1145/3313831.3376445)
- ğŸ“œ [Building Trustworthy AI Solutions: A Case for Practical Solutions for Small Businesses](https://ieeexplore.ieee.org/document/9658213)
- ğŸ“œ [Microsoft Azure AI Security Risk Assessment](https://github.com/Azure/AI-Security-Risk-Assessment/blob/main/AI_Risk_Assessment_v4.1.4.pdf)
- ğŸ“œ [Datasheets for Datasets](https://arxiv.org/pdf/1803.09010.pdf)
- ğŸ¬ [Lies, Distortions, and Misrepresentations in Visualisation](https://www.youtube.com/watch?v=IFA-3uXEcb0) (Michael Correll discusses bad practice in data visualisation that can mislead and audience)
- ğŸ¬ [Use of Colour](https://www.youtube.com/watch?v=AiD6etOB6qI) (Cole Knafflic talks about the use of colour in good data vis design)
- ğŸ¬ [Use of Contrast](https://www.youtube.com/watch?v=60KiAXbkrl0) (Cole Knafflic talks about the use of contrast in good data vis design)
- ğŸ¬ [How to Declutter](https://www.youtube.com/watch?v=X79o46W5plI) (Cole Knafflic talks about how to declutter in good data vis design)
- ğŸ“– [Interpretable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/intro.html)

## Legal, Ethical, & Social Implications

- ğŸ“œ [The Top 10 Risks of Machine Learning Security](https://ieeexplore.ieee.org/document/9107290)
- ğŸ“œ [On the Dangers of Stochastic Parrots](https://dl.acm.org/doi/10.1145/3442188.3445922)

[^1]: This work is a direct result of working on the ERDF Greater Manchester AI Foundry which is part funded by the European Regional Development Fund.
